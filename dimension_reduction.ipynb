{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9916/9916 [00:22<00:00, 435.53it/s]\n",
      "100%|██████████| 154/154 [00:00<00:00, 414.48it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# path to Git Repo from Google CoLab file\n",
    "path = './'\n",
    "root_path = path if os.path.isdir(path) else ''\n",
    "data_dir = os.path.join(root_path, 'training')\n",
    "\n",
    "dimension_reduced_data = os.path.join(root_path, 'dimension_reduced_data')\n",
    "if not os.path.exists(dimension_reduced_data):\n",
    "    os.makedirs(dimension_reduced_data)\n",
    "\n",
    "initial_transforms = transforms.Compose([\n",
    "    transforms.Resize((244, 244)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(data_dir, transform=initial_transforms)\n",
    "\n",
    "def get_mean_std(loader):\n",
    "    num_pixels = 0\n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    images: torch.Tensor\n",
    "    for images, _ in loader:\n",
    "        batch_size, num_channels, height, width = images.shape\n",
    "        num_pixels += batch_size * height * width\n",
    "        mean += images.mean(axis=(0, 2, 3)).sum()\n",
    "        std += images.std(axis=(0, 2, 3)).sum()\n",
    "\n",
    "    mean /= num_pixels\n",
    "    std /= num_pixels\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "batch_size = 32\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "mean, std = get_mean_std(loader)\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((244, 244)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(data_dir, transform=data_transforms)\n",
    "\n",
    "class_to_idx = dataset.class_to_idx\n",
    "with open(os.path.join(dimension_reduced_data, 'class_to_idx.pkl'), 'wb') as handle:\n",
    "    pickle.dump(class_to_idx, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "class_names = [idx_to_class[i] for i in range(len(idx_to_class))]\n",
    "\n",
    "np.save(os.path.join(dimension_reduced_data, 'class_names.npy'), class_names)\n",
    "\n",
    "n_train = len(dataset)\n",
    "X_train = np.zeros((n_train, 3, 244, 244))\n",
    "y_train = np.zeros(n_train)\n",
    "\n",
    "for i, (inputs, labels) in enumerate(tqdm(dataset)):\n",
    "    X_train[i] = inputs.numpy()\n",
    "    y_train[i] = labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_dir = os.path.join(root_path, 'validation')\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((244, 244)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "val_dataset = datasets.ImageFolder(data_dir, transform=data_transforms)\n",
    "\n",
    "n_val = len(val_dataset)\n",
    "X_val = np.zeros((n_val, 3, 244, 244))\n",
    "y_val = np.zeros(n_val)\n",
    "\n",
    "for i, (inputs, labels) in enumerate(tqdm(val_dataset)):\n",
    "    X_val[i] = inputs.numpy()\n",
    "    y_val[i] = labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_val, d1, d2, d3 = X_val.shape\n",
    "X_val = X_val.reshape((n_val, d1 * d2 * d3))\n",
    "\n",
    "n_train, d1, d2, d3 = X_train.shape\n",
    "X_train = X_train.reshape((n_train, d1 * d2 * d3))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "np.save(os.path.join(dimension_reduced_data, 'y_train.npy'), y_train)\n",
    "np.save(os.path.join(dimension_reduced_data, 'y_val.npy'), y_val)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "apply_pca = True\n",
    "apply_lda = True\n",
    "\n",
    "if apply_pca:\n",
    "    pca = PCA(0.90) \n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_val = pca.transform(X_val)\n",
    "    # with open(os.path.join(dimension_reduced_data, 'pca_model.pkl'), 'wb') as handle:\n",
    "    #     pickle.dump(pca, handle)\n",
    "    np.save(os.path.join(dimension_reduced_data, 'X_train_pca.npy'), X_train)\n",
    "    np.save(os.path.join(dimension_reduced_data, 'X_val_pca.npy'), X_val)\n",
    "\n",
    "if apply_lda:\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    X_train = lda.fit_transform(X_train, y_train)\n",
    "    X_val = lda.transform(X_val)\n",
    "\n",
    "    if apply_pca:\n",
    "        # with open(os.path.join(dimension_reduced_data, 'pca_lda_model.pkl'), 'wb') as handle:\n",
    "        #     pickle.dump(lda, handle)\n",
    "\n",
    "        np.save(os.path.join(dimension_reduced_data, 'X_train_pca_lda.npy'), X_train)\n",
    "        np.save(os.path.join(dimension_reduced_data, 'X_val_pca_lda.npy'), X_val)\n",
    "     \n",
    "    else:\n",
    "        # with open(os.path.join(dimension_reduced_data, 'lda_model.pkl'), 'wb') as handle:\n",
    "        #     pickle.dump(lda, handle)\n",
    "        np.save(os.path.join(dimension_reduced_data, 'X_train_lda.npy'), X_train)\n",
    "        np.save(os.path.join(dimension_reduced_data, 'X_val_lda.npy'), X_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
