{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "This notebook manages the data pipeline and performs feature extraction for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Invalid requirement: '...'\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from math import ceil, floor\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from autocrop import Cropper\n",
    "from torchvision import transforms\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = ''\n",
    "train_path = train_path = os.path.join(root_path, 'train')\n",
    "grade_path = os.path.join(root_path, 'grade')\n",
    "\n",
    "os.makedirs(train_path, exist_ok=True)\n",
    "os.makedirs(grade_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline\n",
    "Preparing the data for feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop Data\n",
    "The sorted images will be cropped and saved in testing/ <br>\n",
    "Data will be put into subdirectories organized by labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/156 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:02<00:00, 72.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rejected images: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "src = os.path.join(root_path, 'training_validation_set_0226')\n",
    "dst = os.path.join(train_path, 'testing')\n",
    "\n",
    "rej = os.path.join(train_path, 'rejected')\n",
    "\n",
    "os.makedirs(dst, exist_ok=True)\n",
    "os.makedirs(rej, exist_ok=True)\n",
    "\n",
    "# autocropper\n",
    "cropper = Cropper(244, 244)\n",
    "\n",
    "rejected_count = 0\n",
    "\n",
    "for filename in tqdm(os.listdir(src)):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "        # crops image\n",
    "        cropped_array = cropper.crop(f'{src}/{filename}')\n",
    "\n",
    "        if type(cropped_array) != type(None):\n",
    "            # saves successfully cropped image in subdir\n",
    "            img = Image.fromarray(cropped_array)\n",
    "            img.save(f'{dst}/{filename}')\n",
    "        else:\n",
    "            rejsubdir = os.path.join(rej, 'testing')\n",
    "            os.makedirs(rejsubdir, exist_ok=True)\n",
    "\n",
    "            # saves rejected image in rejected/testing/\n",
    "            img = Image.open(f'{src}/{filename}')\n",
    "            img.save(f'{rejsubdir}/{filename}')\n",
    "\n",
    "            rejected_count += 1\n",
    "\n",
    "print(f'Number of rejected images: {rejected_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rejected Data\n",
    "Manually crops rejected data that autocropper could not recognize <br>\n",
    "The data will be saved to train/testing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = os.path.join(train_path, 'rejected', 'testing')\n",
    "dst = os.path.join(train_path, 'testing')\n",
    "\n",
    "cropped = os.path.join(train_path, 'rejected', 'testing_cropped')\n",
    "\n",
    "os.makedirs(dst, exist_ok=True)\n",
    "os.makedirs(cropped, exist_ok=True)\n",
    "\n",
    "for file in os.listdir(src):\n",
    "    img = Image.open(f'{src}/{file}')\n",
    "    w, h = img.size\n",
    "\n",
    "    left = 0\n",
    "    right = w\n",
    "    top = floor((h - w) / 2)\n",
    "    bottom = h - ceil((h - w) / 2)\n",
    "\n",
    "    img = img.crop((left, top, right, bottom))\n",
    "    img = img.resize((244, 244))\n",
    "    \n",
    "    img.save(f'{dst}/{file}')\n",
    "    img.save(f'{cropped}/{file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PCA, LDA, SVM Models and Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./train/dimension_reduced_data/pca.pkl', 'rb') as f:\n",
    "    pca = pickle.load(f)\n",
    "\n",
    "with open('./train/dimension_reduced_data/lda.pkl', 'rb') as f:\n",
    "    lda = pickle.load(f)\n",
    "\n",
    "with open('./train/dimension_reduced_data/standardScaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "with open('./train/dimension_reduced_data/svm.pkl', 'rb') as f:\n",
    "    svm_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/155 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:557: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "  0%|          | 0/155 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 1 features, but LinearDiscriminantAnalysis is expecting 563 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m image_array \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mfit_transform(image_array)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# image_array = pca.transform(image_array)\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m image_array \u001b[38;5;241m=\u001b[39m \u001b[43mlda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Predict the class\u001b[39;00m\n\u001b[1;32m     43\u001b[0m predicted_class \u001b[38;5;241m=\u001b[39m svm_model\u001b[38;5;241m.\u001b[39mpredict(image_array)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_set_output.py:273\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 273\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    276\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    277\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    278\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    279\u001b[0m         )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:674\u001b[0m, in \u001b[0;36mLinearDiscriminantAnalysis.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    672\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    673\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 674\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    677\u001b[0m     X_new \u001b[38;5;241m=\u001b[39m (X \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxbar_) \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscalings_\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 1 features, but LinearDiscriminantAnalysis is expecting 563 features as input."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_path = './train/testing/'\n",
    "resolution = 50  # Ensure this matches what you used in training\n",
    "initial_transforms = transforms.Compose([\n",
    "    transforms.Resize((resolution, resolution)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "with open('./train/dimension_reduced_data/class_to_idx.pkl', 'rb') as f:\n",
    "    class_to_idx = pickle.load(f)\n",
    "\n",
    "# Invert the dictionary to create an index to class mapping\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "\n",
    "predictions = []\n",
    "\n",
    "# Process each image in the test dataset\n",
    "for image_name in tqdm(os.listdir(test_path)):\n",
    "    if image_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "        image_path = os.path.join(test_path, image_name)\n",
    "        image = Image.open(image_path)\n",
    "        image = initial_transforms(image)\n",
    "\n",
    "        # Convert image to numpy array\n",
    "        image_array = np.array(image).reshape(1, -1)\n",
    "        image_array = image_array.reshape((image_array.shape[0], -1))\n",
    "        \n",
    "        # Apply the same preprocessing as done for training data\n",
    "        image_array = scaler.transform(image_array)\n",
    "        image_array = pca.transform(image_array)\n",
    "        image_array = lda.transform(image_array)\n",
    "        \n",
    "        # Predict the class\n",
    "        predicted_class = svm_model.predict(image_array)\n",
    "        \n",
    "        # Store the results\n",
    "        predictions.append([image_name, idx_to_class[int(predicted_class[0])]])\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "predictions_df = pd.DataFrame(predictions, columns=['filename', 'predictions'])\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "predictions_df.to_csv('./grade/predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "src = 'training_validation_set_0226'\n",
    "\n",
    "def is_image_file(filename: str) -> bool:\n",
    "    extensions = ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG']\n",
    "    return any(filename.endswith(extension) for extension in extensions)\n",
    "\n",
    "# mapping from filename to label\n",
    "filename_to_label = {}\n",
    "\n",
    "# mapping from filename to PIL Image object\n",
    "filename_to_img = {}\n",
    "\n",
    "# mapping from label to list of image files\n",
    "label_to_filenames = defaultdict(list)\n",
    "\n",
    "with open(src + '/file_mapping.txt') as file_mapping:\n",
    "    for line in file_mapping:\n",
    "        filename, label = line.split()\n",
    "        if is_image_file(filename):\n",
    "            filename_to_label[filename] = label\n",
    "            filename_to_img[filename] = Image.open(f'{src}/{filename}')\n",
    "            label_to_filenames[label].append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file:0208_26.jpeg\tpred:lozanoroberto\t\t\ttruth:vennavellirajashekarreddy\n",
      "\t\t\tpred:9\t\t\t\ttruth:24\n",
      "\n",
      "file:0208_10.jpeg\tpred:zuluagagonzalezisabel\t\t\ttruth:yashasvi\n",
      "\t\t\tpred:31\t\t\t\ttruth:27\n",
      "\n",
      "file:0220_19.jpeg\tpred:liuhongji\t\t\ttruth:banmingkai\n",
      "\t\t\tpred:8\t\t\t\ttruth:1\n",
      "\n",
      "rejected\n",
      "file:0208_16.jpeg\tpred:chientingwei\t\t\ttruth:chenziang\n",
      "\t\t\tpred:3\t\t\t\ttruth:2\n",
      "\n",
      "file:0220_29.jpeg\tpred:perambuduruvishnu\t\t\ttruth:sampagaonrahul\n",
      "\t\t\tpred:14\t\t\t\ttruth:17\n",
      "\n",
      "file:0220_30.jpeg\tpred:lozanoroberto\t\t\ttruth:vennavellirajashekarreddy\n",
      "\t\t\tpred:9\t\t\t\ttruth:24\n",
      "\n",
      "file:0208_15.jpeg\tpred:virvadianisargjyotin\t\t\ttruth:lozanoroberto\n",
      "\t\t\tpred:25\t\t\t\ttruth:9\n",
      "\n",
      "rejected\n",
      "file:0220_11.jpeg\tpred:chientingwei\t\t\ttruth:huangjiaoyan\n",
      "\t\t\tpred:3\t\t\t\ttruth:5\n",
      "\n",
      "file:0208_2.jpeg\tpred:virvadianisargjyotin\t\t\ttruth:chientingwei\n",
      "\t\t\tpred:25\t\t\t\ttruth:3\n",
      "\n",
      "file:0222_3.jpeg\tpred:zhouchuandi\t\t\ttruth:selinayu\n",
      "\t\t\tpred:29\t\t\t\ttruth:18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rejected_files = [\n",
    "    '0208_16.jpeg',\n",
    "    '0215_3.jpeg',\n",
    "    '0220_11.jpeg',\n",
    "    '0222_25.jpeg'\n",
    "]\n",
    "\n",
    "with open('grade/predictions.csv') as predictions:\n",
    "    for line in predictions:\n",
    "        file, label = line.split(',')\n",
    "        if is_image_file(file):\n",
    "            ground_truth: str\n",
    "            ground_truth = filename_to_label[file]\n",
    "\n",
    "            if ground_truth.strip() != label.strip():\n",
    "                if file in rejected_files:\n",
    "                    print('rejected')\n",
    "                    \n",
    "                print(f'file:{file}\\tpred:{label.strip()}\\t\\t\\ttruth:{ground_truth.strip()}')\n",
    "                pred = class_to_idx[label.strip()]\n",
    "                truth = class_to_idx[ground_truth.strip()]\n",
    "                print(f'\\t\\t\\tpred:{pred}\\t\\t\\t\\ttruth:{truth}')\n",
    "                print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
