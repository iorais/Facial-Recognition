{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "This notebook manages the data pipeline and performs feature extraction for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Invalid requirement: '...'\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from math import ceil, floor\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from autocrop import Cropper\n",
    "from torchvision import transforms\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = ''\n",
    "train_path = train_path = os.path.join(root_path, 'train')\n",
    "grade_path = os.path.join(root_path, 'grade')\n",
    "\n",
    "os.makedirs(train_path, exist_ok=True)\n",
    "os.makedirs(grade_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline\n",
    "Preparing the data for feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop Data\n",
    "The sorted images will be cropped and saved in testing/ <br>\n",
    "Data will be put into subdirectories organized by labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:02<00:00, 71.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rejected images: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "src = os.path.join(root_path, 'training_validation_set_0226')\n",
    "dst = os.path.join(train_path, 'testing')\n",
    "\n",
    "rej = os.path.join(train_path, 'rejected')\n",
    "\n",
    "os.makedirs(dst, exist_ok=True)\n",
    "os.makedirs(rej, exist_ok=True)\n",
    "\n",
    "# autocropper\n",
    "cropper = Cropper(244, 244)\n",
    "\n",
    "rejected_count = 0\n",
    "\n",
    "for filename in tqdm(os.listdir(src)):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "        # crops image\n",
    "        cropped_array = cropper.crop(f'{src}/{filename}')\n",
    "\n",
    "        if type(cropped_array) != type(None):\n",
    "            # saves successfully cropped image in subdir\n",
    "            img = Image.fromarray(cropped_array)\n",
    "            img.save(f'{dst}/{filename}')\n",
    "        else:\n",
    "            rejsubdir = os.path.join(rej, 'testing')\n",
    "            os.makedirs(rejsubdir, exist_ok=True)\n",
    "\n",
    "            # saves rejected image in rejected/testing/\n",
    "            img = Image.open(f'{src}/{filename}')\n",
    "            img.save(f'{rejsubdir}/{filename}')\n",
    "\n",
    "            rejected_count += 1\n",
    "\n",
    "print(f'Number of rejected images: {rejected_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rejected Data\n",
    "Manually crops rejected data that autocropper could not recognize <br>\n",
    "The data will be saved to train/testing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = os.path.join(train_path, 'rejected', 'testing')\n",
    "dst = os.path.join(train_path, 'testing')\n",
    "\n",
    "cropped = os.path.join(train_path, 'rejected', 'testing_cropped')\n",
    "\n",
    "os.makedirs(dst, exist_ok=True)\n",
    "os.makedirs(cropped, exist_ok=True)\n",
    "\n",
    "for file in os.listdir(src):\n",
    "    img = Image.open(f'{src}/{file}')\n",
    "    w, h = img.size\n",
    "\n",
    "    left = 0\n",
    "    right = w\n",
    "    top = floor((h - w) / 2)\n",
    "    bottom = h - ceil((h - w) / 2)\n",
    "\n",
    "    img = img.crop((left, top, right, bottom))\n",
    "    img = img.resize((244, 244))\n",
    "    \n",
    "    img.save(f'{dst}/{file}')\n",
    "    img.save(f'{cropped}/{file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PCA, LDA, SVM Models and Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./train/dimension_reduced_data/pca.pkl', 'rb') as f:\n",
    "    pca = pickle.load(f)\n",
    "\n",
    "with open('./train/dimension_reduced_data/lda.pkl', 'rb') as f:\n",
    "    lda = pickle.load(f)\n",
    "\n",
    "with open('./train/dimension_reduced_data/standardScaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "with open('./train/dimension_reduced_data/svm.pkl', 'rb') as f:\n",
    "    svm_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 14/155 [00:00<00:01, 133.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ravijayanthidhanasekar\n",
      "vennavellirajashekarreddy\n",
      "amarisian\n",
      "perambuduruvishnu\n",
      "vanderlindenilona\n",
      "lozanoroberto\n",
      "sivarajusairevanth\n",
      "zotaharsh\n",
      "chientingwei\n",
      "sampagaonrahul\n",
      "manglaniroshanlakhi\n",
      "yashasvi\n",
      "zuluagagonzalezisabel\n",
      "somaniachal\n",
      "sivarajusairevanth\n",
      "zhouchuandi\n",
      "pereiranerissagodfrey\n",
      "somaniachal\n",
      "zhangyuanzhen\n",
      "ravijayanthidhanasekar\n",
      "huangjiaoyan\n",
      "chenziang\n",
      "zhouchuandi\n",
      "sampagaonrahul\n",
      "zhouchuandi\n",
      "zhangyuanzhen\n",
      "manglaniroshanlakhi\n",
      "huangjiaoyan\n",
      "zuluagagonzalezisabel\n",
      "liuhongji\n",
      "sivarajusairevanth\n",
      "vanderlindenilona\n",
      "shahmanali\n",
      "zotaharsh\n",
      "selinayu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 45/155 [00:00<00:00, 232.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liuhongji\n",
      "upadhyevaishnavi\n",
      "gowdarachandrashekarappasrivarsha\n",
      "lishumeng\n",
      "selinayu\n",
      "chientingwei\n",
      "liuhongji\n",
      "virvadianisargjyotin\n",
      "zhangyuanzhen\n",
      "upadhyevaishnavi\n",
      "sivarajusairevanth\n",
      "selinayu\n",
      "manglaniroshanlakhi\n",
      "upadhyevaishnavi\n",
      "mendonakshay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 83/155 [00:00<00:00, 289.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chientingwei\n",
      "perambuduruvishnu\n",
      "ravijayanthidhanasekar\n",
      "huangjiaoyan\n",
      "lozanoroberto\n",
      "gowdarachandrashekarappasrivarsha\n",
      "banmingkai\n",
      "mendonakshay\n",
      "gowdarachandrashekarappasrivarsha\n",
      "wukaiyue\n",
      "sampagaonrahul\n",
      "wukaiyue\n",
      "lishumeng\n",
      "yashasvi\n",
      "zuluagagonzalezisabel\n",
      "virvadianisargjyotin\n",
      "kodipunzulanandini\n",
      "gowdarachandrashekarappasrivarsha\n",
      "vanderlindenilona\n",
      "wukaiyue\n",
      "negiparth\n",
      "ravijayanthidhanasekar\n",
      "ravijayanthidhanasekar\n",
      "mendonakshay\n",
      "zuluagagonzalezisabel\n",
      "perambuduruvishnu\n",
      "mendonakshay\n",
      "zuluagagonzalezisabel\n",
      "virvadianisargjyotin\n",
      "shahmanali\n",
      "chenziang\n",
      "vennavellirajashekarreddy\n",
      "perambuduruvishnu\n",
      "virvadianisargjyotin\n",
      "chenziang\n",
      "somaniachal\n",
      "lishumeng\n",
      "amarisian\n",
      "liuhongji\n",
      "vanderlindenilona\n",
      "kodipunzulanandini\n",
      "lozanoroberto\n",
      "chenziang\n",
      "pereiranerissagodfrey\n",
      "negiparth\n",
      "chientingwei\n",
      "lozanoroberto\n",
      "negiparth\n",
      "pereiranerissagodfrey\n",
      "yashasvi\n",
      "kodipunzulanandini\n",
      "sampagaonrahul\n",
      "lozanoroberto\n",
      "kodipunzulanandini\n",
      "zhouchuandi\n",
      "perambuduruvishnu\n",
      "upadhyevaishnavi\n",
      "banmingkai\n",
      "liuhongji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 124/155 [00:00<00:00, 332.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pereiranerissagodfrey\n",
      "lishumeng\n",
      "virvadianisargjyotin\n",
      "oraisisaac\n",
      "banmingkai\n",
      "mendonakshay\n",
      "chientingwei\n",
      "somaniachal\n",
      "kodipunzulanandini\n",
      "upadhyevaishnavi\n",
      "amarisian\n",
      "virvadianisargjyotin\n",
      "vennavellirajashekarreddy\n",
      "zhouchuandi\n",
      "liuhongji\n",
      "pereiranerissagodfrey\n",
      "lishumeng\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155/155 [00:00<00:00, 294.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wukaiyue\n",
      "gowdarachandrashekarappasrivarsha\n",
      "zhouchuandi\n",
      "manglaniroshanlakhi\n",
      "huangjiaoyan\n",
      "manglaniroshanlakhi\n",
      "oraisisaac\n",
      "selinayu\n",
      "chientingwei\n",
      "oraisisaac\n",
      "negiparth\n",
      "shahmanali\n",
      "somaniachal\n",
      "zotaharsh\n",
      "zotaharsh\n",
      "banmingkai\n",
      "zuluagagonzalezisabel\n",
      "oraisisaac\n",
      "negiparth\n",
      "chenziang\n",
      "amarisian\n",
      "virvadianisargjyotin\n",
      "shahmanali\n",
      "shahmanali\n",
      "oraisisaac\n",
      "zhangyuanzhen\n",
      "yashasvi\n",
      "amarisian\n",
      "perambuduruvishnu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_path = './train/testing/'\n",
    "resolution = 50  # Ensure this matches what you used in training\n",
    "initial_transforms = transforms.Compose([\n",
    "    transforms.Resize((resolution, resolution)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "with open('./train/dimension_reduced_data/class_to_idx.pkl', 'rb') as f:\n",
    "    class_to_idx = pickle.load(f)\n",
    "\n",
    "# Invert the dictionary to create an index to class mapping\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "\n",
    "predictions = []\n",
    "\n",
    "# Process each image in the test dataset\n",
    "for image_name in tqdm(os.listdir(test_path)):\n",
    "    if image_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "        image_path = os.path.join(test_path, image_name)\n",
    "        image = Image.open(image_path)\n",
    "        image = initial_transforms(image)\n",
    "\n",
    "        # Convert image to numpy array\n",
    "        image_array = np.array(image).reshape(1, -1)\n",
    "        image_array = image_array.reshape((image_array.shape[0], -1))\n",
    "        \n",
    "        # Apply the same preprocessing as done for training data\n",
    "        image_array = scaler.transform(image_array)\n",
    "        image_array = pca.transform(image_array)\n",
    "        image_array = lda.transform(image_array)\n",
    "        \n",
    "        # Predict the class\n",
    "        predicted_class = svm_model.predict(image_array)\n",
    "        \n",
    "        # Store the results\n",
    "        predictions.append([image_name, idx_to_class[int(predicted_class[0])]])\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "predictions_df = pd.DataFrame(predictions, columns=['FileName', 'PredictedClass'])\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "predictions_df.to_csv('./grade/predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155/155 [00:00<00:00, 1640.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define the path for your testing images\n",
    "test_path = './train/testing/'\n",
    "\n",
    "# Initialize the same transform you used for your training data\n",
    "resolution = 50  # Ensure this matches what you used in training\n",
    "initial_transforms = transforms.Compose([\n",
    "    transforms.Resize((resolution, resolution)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Process the test images\n",
    "X_test = []\n",
    "files = [f for f in os.listdir(test_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "for file in tqdm(files):\n",
    "    image_path = os.path.join(test_path, file)\n",
    "    image = Image.open(image_path)\n",
    "    image = initial_transforms(image)\n",
    "    image = np.array(image)\n",
    "    X_test.append(image)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "n, d1, d2, d3 = X_test.shape\n",
    "X_test = X_test.reshape((n, d1 * d2 * d3))\n",
    "\n",
    "# Normalize the data\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Apply PCA and LDA transformations\n",
    "X_test = pca.transform(X_test)\n",
    "X_test = lda.transform(X_test)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# predictions now contains the predicted labels for your test data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
