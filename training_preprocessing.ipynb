{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "This notebook manages the data pipeline and performs feature extraction for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import torch.utils.data\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from tqdm import tqdm\n",
    "from autocrop import Cropper\n",
    "from torchvision import transforms\n",
    "from collections import defaultdict\n",
    "from PIL import Image, ImageEnhance\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline\n",
    "Preparing the data for feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort Data\n",
    "The raw image files will be renamed, labeled, and saved in sorted_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excluding wufangyuan\n",
      "finished sorting data\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(root_path,'trainingset0206')\n",
    "train_dst = os.path.join(root_path, 'sorted_data')\n",
    "\n",
    "src = train_path\n",
    "dst = train_dst\n",
    "\n",
    "def is_image_file(filename: str) -> bool:\n",
    "    extensions = ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG']\n",
    "    return any(filename.endswith(extension) for extension in extensions)\n",
    "\n",
    "# mapping from filename to label\n",
    "filename_to_label = {}\n",
    "\n",
    "# mapping from filename to PIL Image object\n",
    "filename_to_img = {}\n",
    "\n",
    "# mapping from label to list of image files\n",
    "label_to_filenames = defaultdict(list)\n",
    "\n",
    "with open(src + '/file_mapping.txt') as file_mapping:\n",
    "    for line in file_mapping:\n",
    "        filename, label = line.split()\n",
    "        if is_image_file(filename):\n",
    "            filename_to_label[filename] = label\n",
    "            filename_to_img[filename] = Image.open(f'{src}/{filename}')\n",
    "            label_to_filenames[label].append(filename)\n",
    "\n",
    "for label in label_to_filenames.keys():\n",
    "    label_to_filenames[label].sort()\n",
    "\n",
    "# list of labels\n",
    "labels = list(label_to_filenames.keys())\n",
    "\n",
    "def save_image(filename: str):\n",
    "    # create parent directory if needed\n",
    "    parent = os.path.join(root_path, dst)\n",
    "    os.makedirs(parent, exist_ok=True)\n",
    "\n",
    "    img = filename_to_img[filename]\n",
    "\n",
    "    label = filename_to_label[filename]\n",
    "    date = filename.split('_')[0]\n",
    "    new_filename = '_'.join([label, date + '.jpeg'])\n",
    "\n",
    "    img.save(f'{parent}/{new_filename}')\n",
    "\n",
    "# main function\n",
    "def sort_data():\n",
    "    exclude_labels = ['wufangyuan']\n",
    "    exclude = defaultdict(lambda : False)\n",
    "    for label in exclude_labels:\n",
    "        exclude[label] = True\n",
    "\n",
    "    for label in label_to_filenames.keys():\n",
    "        if exclude[label]:\n",
    "            print(f'excluding {label}')\n",
    "            continue\n",
    "        \n",
    "        for filename in label_to_filenames[label]:\n",
    "            save_image(filename)\n",
    "\n",
    "    print('finished sorting data')\n",
    "\n",
    "sort_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment Data\n",
    "The labled images will be augmented and saved in augmented_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment Image Color\n",
    "helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_image_properties_opencv(image_path, \n",
    "                                   output_folder, \n",
    "                                   saturation_factor, \n",
    "                                   brightness_factor, \n",
    "                                   contrast_factor, \n",
    "                                   hue_shift_value):\n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        base_name = os.path.basename(image_path)\n",
    "        file_name, extension_type = base_name.split(\".\")\n",
    "\n",
    "        hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        h, s, v = cv2.split(hsv_image)\n",
    "\n",
    "        h = (h + hue_shift_value) % 180 \n",
    "        hsv_image = cv2.merge([h, s, v])\n",
    "\n",
    "        adjusted_image = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2BGR)\n",
    "        adjusted_image_pil = Image.fromarray(cv2.cvtColor(adjusted_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        enhancer = ImageEnhance.Color(adjusted_image_pil)\n",
    "        adjusted_image_pil = enhancer.enhance(saturation_factor)\n",
    "\n",
    "        enhancer = ImageEnhance.Brightness(adjusted_image_pil)\n",
    "        adjusted_image_pil = enhancer.enhance(brightness_factor)\n",
    "\n",
    "        enhancer = ImageEnhance.Contrast(adjusted_image_pil)\n",
    "        adjusted_image_pil = enhancer.enhance(contrast_factor)\n",
    "\n",
    "        color_adjusted_filename = f\"{file_name}_h{round(hue_shift_value,2)}_s{round(saturation_factor,2)}_b{round(brightness_factor,2)}_c{round(contrast_factor,2)}.{extension_type}\"\n",
    "        color_adjusted_path = os.path.join(output_folder, color_adjusted_filename)\n",
    "        adjusted_image_pil.save(color_adjusted_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "def aug_image_color_process_folder(folder_path, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    filename: str\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            hue_range = [10 * i for i in range(1)]  # hue shift locked to 10\n",
    "            saturation_range = [0.9 + 0.3*i for i in range(2)]  # range from 0.9 to 1.5\n",
    "            brightness_range = [0.6 + 0.5*i for i in range(2)]  # range from 0.6 to 1.6\n",
    "            contrast_range = [0.8 + 0.5*i for i in range(2)]  # range from 0.8 to 1.6\n",
    "\n",
    "            for hue_shift_value in hue_range:\n",
    "                for saturation_factor in saturation_range:\n",
    "                    for brightness_factor in brightness_range:\n",
    "                        for contrast_factor in contrast_range:\n",
    "                            adjust_image_properties_opencv(file_path, \n",
    "                                                           output_folder, \n",
    "                                                           saturation_factor, \n",
    "                                                           brightness_factor, \n",
    "                                                           contrast_factor, \n",
    "                                                           hue_shift_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment Image Tilt\n",
    "helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tilt_right(image):\n",
    "    rows, cols = image.shape[:2]\n",
    "    tilt_matrix = np.float32([[1, 0.2, 0], [0, 1, 0]])\n",
    "    # Adjust translation to fit the entire tilted image within the original dimensions\n",
    "    translation_matrix = np.float32([[1, 0, -0.2 * cols], [0, 1, 0]])\n",
    "    combined_matrix = np.dot(tilt_matrix, np.vstack((translation_matrix, [0, 0, 1])))\n",
    "    # Warp the image\n",
    "    tilted_image = cv2.warpAffine(image, combined_matrix[:2, :], (cols, rows))\n",
    "    return tilted_image\n",
    "\n",
    "def tilt_left(image):\n",
    "    rows, cols = image.shape[:2]\n",
    "    tilt_matrix = np.float32([[1, -0.2, 0], [0, 1, 0]])\n",
    "    # Adjust translation to fit the entire tilted image within the original dimensions\n",
    "    translation_matrix = np.float32([[1, 0, 0.2 * cols], [0, 1, 0]])\n",
    "    combined_matrix = np.dot(tilt_matrix, np.vstack((translation_matrix, [0, 0, 1])))\n",
    "    # Warp the image\n",
    "    tilted_image = cv2.warpAffine(image, combined_matrix[:2, :], (cols, rows))\n",
    "    return tilted_image\n",
    "\n",
    "def tilt_front(image):\n",
    "    rows, cols = image.shape[:2]\n",
    "    tilt_matrix = np.float32([[1, 0, 0], [0, 1, 0]])\n",
    "    tilted_image = cv2.warpAffine(image, tilt_matrix, (cols, rows))\n",
    "    return tilted_image\n",
    "\n",
    "def tilt_back(image):\n",
    "    rows, cols = image.shape[:2]\n",
    "    tilt_matrix = np.float32([[-1, 0, cols], [0, 1, 0]])\n",
    "    tilted_image = cv2.warpAffine(image, tilt_matrix, (cols, rows))\n",
    "    return tilted_image\n",
    "\n",
    "def aug_image_tilt_process_folder(folder_path, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    filename: str\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            image = mpimg.imread(file_path)\n",
    "\n",
    "            # tilt images\n",
    "            tilted_right = tilt_right(image)\n",
    "            tilted_left = tilt_left(image)\n",
    "            tilted_front = tilt_front(image)\n",
    "            tilted_back = tilt_back(image)\n",
    "\n",
    "            # save tilted iamges\n",
    "            name, ext = filename.split('.')\n",
    "            mpimg.imsave(fname=os.path.join(output_folder, f'{name}_tilted_right.{ext}'), arr=tilted_right)\n",
    "            mpimg.imsave(fname=os.path.join(output_folder, f'{name}_tilted_left.{ext}'), arr=tilted_left)\n",
    "            mpimg.imsave(fname=os.path.join(output_folder, f'{name}_tilted_front.{ext}'), arr=tilted_front)\n",
    "            mpimg.imsave(fname=os.path.join(output_folder, f'{name}_tilted_back.{ext}'), arr=tilted_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinations of Augmentation\n",
    "The labled images are tilted, colored, and saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory of sorted, labled data\n",
    "sorted_path = os.path.join(root_path, 'sorted_data')\n",
    "\n",
    "# create directory for augmented data\n",
    "aug_path = os.path.join(root_path, 'augmented_data')\n",
    "os.makedirs(aug_path, exist_ok=True)\n",
    "\n",
    "# saves default data into augmented_data subdirectory\n",
    "for filename in os.listdir(sorted_path):\n",
    "    file_path = os.path.join(sorted_path, filename)\n",
    "\n",
    "    img = Image.open(file_path)\n",
    "    img.save(f'{aug_path}/{filename}')\n",
    "\n",
    "# saves tilted images into augmented_data subdirectories\n",
    "aug_subdir_tilt = os.path.join(aug_path, 'Tilt')\n",
    "aug_image_tilt_process_folder(sorted_path, aug_subdir_tilt)\n",
    "aug_image_tilt_process_folder(sorted_path, aug_path)\n",
    "\n",
    "# saves colored images into augmented_data subdirectory\n",
    "aug_subdir_colored = os.path.join(aug_path, 'Colored')\n",
    "aug_image_color_process_folder(sorted_path, aug_subdir_colored)\n",
    "aug_image_color_process_folder(aug_subdir_tilt, aug_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop Data\n",
    "The augmented images will be cropped and saved in training/ <br>\n",
    "Data will be put into subdirectories organized by labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(root_path, 'sorted_data')\n",
    "train_dst = os.path.join(root_path, 'training')\n",
    "rej_path = os.path.join(root_path, 'rejected')\n",
    "\n",
    "src = train_path\n",
    "dst = train_dst\n",
    "\n",
    "rej = os.path.join(rej_path, dst)\n",
    "\n",
    "os.makedirs(dst, exist_ok=True)\n",
    "os.makedirs(rej, exist_ok=True)\n",
    "\n",
    "# autocropper\n",
    "cropper = Cropper(224, 224)\n",
    "\n",
    "for filename in tqdm(os.listdir(src)):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "        # creates subdirectory by labels\n",
    "        label = filename.split('_')[0]\n",
    "        subdir = os.path.join(dst, label)\n",
    "        os.makedirs(subdir, exist_ok=True)\n",
    "\n",
    "        # crops image\n",
    "        cropped_array = cropper.crop(f'{src}/{filename}')\n",
    "        print(f'attempting to save {src}/{filename}')\n",
    "\n",
    "        if type(cropped_array) != type(None):\n",
    "            # saves successfully cropped image in subdir\n",
    "            img = Image.fromarray(cropped_array)\n",
    "            img.save(f'{subdir}/{filename}')\n",
    "            print(f'saved to {subdir}/{filename}')\n",
    "        else:\n",
    "            rejsubdir = os.path.join(rej, label)\n",
    "            os.makedirs(rejsubdir, exist_ok=True)\n",
    "\n",
    "            # saves rejected image in rejected/training/[label]/\n",
    "            img = Image.open(f'{src}/{filename}')\n",
    "            img.save(f'{rejsubdir}/{filename}')\n",
    "            print(f'rejected to {rejsubdir}/{filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rejected Data [*might delete this for training]\n",
    "Handles rejected data that autocropper could not recognize <br>\n",
    "The data will be saved to training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "Extracts important features from data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(root_path, 'training')\n",
    "dimension_reduced_data = os.path.join(root_path, 'dimension_reduced_data')\n",
    "\n",
    "if not os.path.exists(dimension_reduced_data):\n",
    "    os.makedirs(dimension_reduced_data)\n",
    "\n",
    "initial_transforms = transforms.Compose([\n",
    "    transforms.Resize((244, 244)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(data_dir, transform=initial_transforms)\n",
    "\n",
    "def get_mean_std(loader):\n",
    "    num_pixels = 0\n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    images: torch.Tensor\n",
    "    for images, _ in loader:\n",
    "        batch_size, num_channels, height, width = images.shape\n",
    "        num_pixels += batch_size * height * width\n",
    "        mean += images.mean(axis=(0, 2, 3)).sum()\n",
    "        std += images.std(axis=(0, 2, 3)).sum()\n",
    "\n",
    "    mean /= num_pixels\n",
    "    std /= num_pixels\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "batch_size = 32\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "mean, std = get_mean_std(loader)\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((244, 244)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(data_dir, transform=data_transforms)\n",
    "\n",
    "class_to_idx = dataset.class_to_idx\n",
    "with open(os.path.join(dimension_reduced_data, 'class_to_idx.pkl'), 'wb') as handle:\n",
    "    pickle.dump(class_to_idx, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "class_names = [idx_to_class[i] for i in range(len(idx_to_class))]\n",
    "\n",
    "np.save(os.path.join(dimension_reduced_data, 'class_names.npy'), class_names)\n",
    "\n",
    "n_train = len(dataset)\n",
    "X_train = np.zeros((n_train, 3, 244, 244))\n",
    "y_train = np.zeros(n_train)\n",
    "\n",
    "for i, (inputs, labels) in enumerate(tqdm(dataset)):\n",
    "    X_train[i] = inputs.numpy()\n",
    "    y_train[i] = labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_dir = os.path.join(root_path, 'validation')\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((244, 244)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "val_dataset = datasets.ImageFolder(data_dir, transform=data_transforms)\n",
    "\n",
    "n_val = len(val_dataset)\n",
    "X_val = np.zeros((n_val, 3, 244, 244))\n",
    "y_val = np.zeros(n_val)\n",
    "\n",
    "for i, (inputs, labels) in enumerate(tqdm(val_dataset)):\n",
    "    X_val[i] = inputs.numpy()\n",
    "    y_val[i] = labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_val, d1, d2, d3 = X_val.shape\n",
    "X_val = X_val.reshape((n_val, d1 * d2 * d3))\n",
    "\n",
    "n_train, d1, d2, d3 = X_train.shape\n",
    "X_train = X_train.reshape((n_train, d1 * d2 * d3))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "np.save(os.path.join(dimension_reduced_data, 'y_train.npy'), y_train)\n",
    "np.save(os.path.join(dimension_reduced_data, 'y_val.npy'), y_val)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "apply_pca = True\n",
    "apply_lda = True\n",
    "\n",
    "if apply_pca:\n",
    "    pca = PCA(0.90) \n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_val = pca.transform(X_val)\n",
    "    # with open(os.path.join(dimension_reduced_data, 'pca_model.pkl'), 'wb') as handle:\n",
    "    #     pickle.dump(pca, handle)\n",
    "    np.save(os.path.join(dimension_reduced_data, 'X_train_pca.npy'), X_train)\n",
    "    np.save(os.path.join(dimension_reduced_data, 'X_val_pca.npy'), X_val)\n",
    "\n",
    "if apply_lda:\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    X_train = lda.fit_transform(X_train, y_train)\n",
    "    X_val = lda.transform(X_val)\n",
    "\n",
    "    if apply_pca:\n",
    "        # with open(os.path.join(dimension_reduced_data, 'pca_lda_model.pkl'), 'wb') as handle:\n",
    "        #     pickle.dump(lda, handle)\n",
    "\n",
    "        np.save(os.path.join(dimension_reduced_data, 'X_train_pca_lda.npy'), X_train)\n",
    "        np.save(os.path.join(dimension_reduced_data, 'X_val_pca_lda.npy'), X_val)\n",
    "     \n",
    "    else:\n",
    "        # with open(os.path.join(dimension_reduced_data, 'lda_model.pkl'), 'wb') as handle:\n",
    "        #     pickle.dump(lda, handle)\n",
    "        np.save(os.path.join(dimension_reduced_data, 'X_train_lda.npy'), X_train)\n",
    "        np.save(os.path.join(dimension_reduced_data, 'X_val_lda.npy'), X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "Dimension reduction on data for full rank matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA\n",
    "Supervised dimension reduction on data that will be used for training <br>\n",
    "The numpy arrays will be saved in\n",
    "- [dimension_reduced_data/X_train_pca_lda.npy](dimension_reduced_data/X_train_pca_lda.npy)\n",
    "- [dimension_reduced_data/y_train_pca_lda.npy](dimension_reduced_data/y_train_pca_lda.npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
