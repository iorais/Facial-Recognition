{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import configparser\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to Git Repo from Google CoLab file\n",
    "path = 'drive/Shareddrives/CSEN240_Group11/Facial-Recognition'\n",
    "\n",
    "root_path = path if os.path.isdir(path) else ''\n",
    "\n",
    "data_dir = os.path.join(root_path, 'training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataset = datasets.ImageFolder(data_dir, transform=lambda img: np.array(img).astype(float))\n",
    "\n",
    "def get_mean_std(loader):\n",
    "    # Compute the mean and standard deviation of all pixels in the dataset\n",
    "    num_pixels = 0\n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    images: torch.Tensor\n",
    "    for images, _ in loader:\n",
    "        batch_size, num_channels, height, width = images.shape\n",
    "        num_pixels += batch_size * height * width\n",
    "        mean += images.mean(axis=(0, 2, 3)).sum()\n",
    "        std += images.std(axis=(0, 2, 3)).sum()\n",
    "\n",
    "    mean /= num_pixels\n",
    "    std /= num_pixels\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "batch_size = 32\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "mean, std = get_mean_std(loader)\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(data_dir, transform=data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(4 * 500 * 500, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 33)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.double()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    inputs: torch.Tensor\n",
    "    for i, (inputs, labels) in enumerate(tqdm(loader)):\n",
    "        inputs = inputs.permute(0, 3, 1, 2)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(dataset)\n",
    "    print(f\"Epoch {epoch+1} loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dst = os.path.join(root_path, 'models')\n",
    "os.makedirs(model_dst, exist_ok=True)\n",
    "torch.save(model, f'{model_dst}/nn.pth')\n",
    "print('model saved successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128023777\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "model = torch.load('models/nn.pth')\n",
    "model.eval()\n",
    "\n",
    "params = count_parameters(model)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 332/332 [29:00<00:00,  5.24s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Define lists to store predictions and ground truth labels\n",
    "predictions = []\n",
    "ground_truth = []\n",
    "\n",
    "# Iterate over the validation dataset\n",
    "for inputs, labels in tqdm(loader):\n",
    "    inputs = inputs.permute(0, 3, 1, 2)\n",
    "    # Forward pass\n",
    "    with torch.no_grad():  # No need to compute gradients during inference\n",
    "        outputs = model(inputs)\n",
    "    \n",
    "    # Convert outputs to probabilities or class predictions depending on your model\n",
    "    # For example, if your model is a classification model with softmax activation:\n",
    "    probabilities = torch.softmax(outputs, dim=1)\n",
    "    _, predicted_classes = torch.max(probabilities, 1)\n",
    "\n",
    "    # Append predictions and ground truth labels to lists\n",
    "    predictions.append(predicted_classes)\n",
    "    ground_truth.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03473268072289157\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = []\n",
    "for pred, gt in zip(predictions, ground_truth):\n",
    "    p = pred.numpy()\n",
    "    y = gt.numpy()\n",
    "\n",
    "    accuracy = accuracy_score(p, y)\n",
    "    acc.append(accuracy)\n",
    "\n",
    "print(sum(acc)/len(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
