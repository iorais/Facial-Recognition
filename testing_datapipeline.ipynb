{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "This notebook manages the data pipeline and performs feature extraction for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from tqdm import tqdm\n",
    "from autocrop import Cropper\n",
    "from torchvision import transforms\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = ''\n",
    "train_path = train_path = os.path.join(root_path, 'train')\n",
    "grade_path = os.path.join(root_path, 'grade')\n",
    "\n",
    "os.makedirs(train_path, exist_ok=True)\n",
    "os.makedirs(grade_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline\n",
    "Preparing the data for feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop Data\n",
    "The sorted images will be cropped and saved in testing/ <br>\n",
    "Data will be put into subdirectories organized by labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = os.path.join(root_path, 'training_validation_set_0226')\n",
    "dst = os.path.join(train_path, 'testing')\n",
    "\n",
    "rej = os.path.join(train_path, 'rejected')\n",
    "\n",
    "os.makedirs(dst, exist_ok=True)\n",
    "os.makedirs(rej, exist_ok=True)\n",
    "\n",
    "# autocropper\n",
    "cropper = Cropper(244, 244)\n",
    "\n",
    "rejected_count = 0\n",
    "\n",
    "for filename in tqdm(os.listdir(src)):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "\n",
    "\n",
    "        # crops image\n",
    "        cropped_array = cropper.crop(f'{src}/{filename}')\n",
    "\n",
    "        if type(cropped_array) != type(None):\n",
    "            # saves successfully cropped image in subdir\n",
    "            img = Image.fromarray(cropped_array)\n",
    "            img.save(f'{dst}/{filename}')\n",
    "        else:\n",
    "            rejsubdir = os.path.join(rej, dst)\n",
    "            os.makedirs(rejsubdir, exist_ok=True)\n",
    "\n",
    "            # saves rejected image in rejected/training/[label]/\n",
    "            img = Image.open(f'{src}/{filename}')\n",
    "            img.save(f'{rejsubdir}/{filename}')\n",
    "\n",
    "            rejected_count += 1\n",
    "\n",
    "print(f'Number of rejected images: {rejected_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rejected Data\n",
    "Handles rejected data that autocropper could not recognize <br>\n",
    "The data will be saved to testing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "Extracts important features from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(train_path, 'training')\n",
    "dimension_reduced_data = os.path.join(train_path, 'dimension_reduced_data')\n",
    "\n",
    "os.makedirs(dimension_reduced_data, exist_ok=True)\n",
    "\n",
    "initial_transforms = transforms.Compose([\n",
    "    transforms.Resize((244, 244)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(data_dir, transform=initial_transforms)\n",
    "\n",
    "# converts tensor to numpy array\n",
    "n = len(dataset)\n",
    "X = np.zeros((n, 3, 244, 244))\n",
    "y = np.zeros(n)\n",
    "\n",
    "for i, (inputs, labels) in enumerate(tqdm(dataset)):\n",
    "    X[i] = inputs.numpy()\n",
    "    y[i] = labels\n",
    "\n",
    "# class to index dictionary\n",
    "class_to_idx = dataset.class_to_idx\n",
    "with open(os.path.join(dimension_reduced_data, 'class_to_idx.pkl'), 'wb') as handle:\n",
    "    pickle.dump(class_to_idx, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# class names numpy array\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "class_names = [idx_to_class[i] for i in range(len(idx_to_class))]\n",
    "np.save(os.path.join(dimension_reduced_data, 'class_names.npy'), class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, d1, d2, d3 = X.shape\n",
    "X = X.reshape((n, d1 * d2 * d3))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "Dimension reduction on data for full rank matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(0.90) \n",
    "X = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA\n",
    "Supervised dimension reduction on data that will be used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "X = lda.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saves data\n",
    "- labels: [dimension_reduced_data/y.npy](dimension_reduced_data/y.npy)\n",
    "- data: [dimension_reduced_data/X.npy](dimension_reduced_data/X_train_pca_lda.npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(dimension_reduced_data, 'X.npy'), X)\n",
    "np.save(os.path.join(dimension_reduced_data, 'y.npy'), y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
