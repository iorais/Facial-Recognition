{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "This notebook manages the data pipeline and performs feature extraction for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from math import ceil, floor\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from autocrop import Cropper\n",
    "from torchvision import transforms\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = ''\n",
    "train_path = train_path = os.path.join(root_path, 'train')\n",
    "grade_path = os.path.join(root_path, 'grade')\n",
    "\n",
    "os.makedirs(train_path, exist_ok=True)\n",
    "os.makedirs(grade_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline\n",
    "Preparing the data for feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop Data\n",
    "The sorted images will be cropped and saved in testing/ <br>\n",
    "Data will be put into subdirectories organized by labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rejected images: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "src = os.path.join(root_path, 'training_validation_set_0226')\n",
    "dst = os.path.join(train_path, 'testing')\n",
    "\n",
    "rej = os.path.join(train_path, 'rejected')\n",
    "\n",
    "os.makedirs(dst, exist_ok=True)\n",
    "os.makedirs(rej, exist_ok=True)\n",
    "\n",
    "# autocropper\n",
    "cropper = Cropper(244, 244)\n",
    "\n",
    "rejected_count = 0\n",
    "\n",
    "for filename in tqdm(os.listdir(src)):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "        # crops image\n",
    "        cropped_array = cropper.crop(f'{src}/{filename}')\n",
    "\n",
    "        if type(cropped_array) != type(None):\n",
    "            # saves successfully cropped image in subdir\n",
    "            img = Image.fromarray(cropped_array)\n",
    "            img.save(f'{dst}/{filename}')\n",
    "        else:\n",
    "            rejsubdir = os.path.join(rej, 'testing')\n",
    "            os.makedirs(rejsubdir, exist_ok=True)\n",
    "\n",
    "            # saves rejected image in rejected/testing/\n",
    "            img = Image.open(f'{src}/{filename}')\n",
    "            img.save(f'{rejsubdir}/{filename}')\n",
    "\n",
    "            rejected_count += 1\n",
    "\n",
    "print(f'Number of rejected images: {rejected_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rejected Data\n",
    "Manually crops rejected data that autocropper could not recognize <br>\n",
    "The data will be saved to train/testing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = os.path.join(train_path, 'rejected', 'testing')\n",
    "dst = os.path.join(train_path, 'testing')\n",
    "\n",
    "cropped = os.path.join(train_path, 'rejected', 'testing_cropped')\n",
    "\n",
    "os.makedirs(dst, exist_ok=True)\n",
    "os.makedirs(cropped, exist_ok=True)\n",
    "\n",
    "for file in os.listdir(src):\n",
    "    img = Image.open(f'{src}/{file}')\n",
    "    w, h = img.size\n",
    "\n",
    "    left = 0\n",
    "    right = w\n",
    "    top = floor((h - w) / 2)\n",
    "    bottom = h - ceil((h - w) / 2)\n",
    "\n",
    "    img = img.crop((left, top, right, bottom))\n",
    "    img = img.resize((244, 244))\n",
    "    \n",
    "    img.save(f'{dst}/{file}')\n",
    "    img.save(f'{cropped}/{file}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
